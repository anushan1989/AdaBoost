{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anushan1989/AdaBoost/blob/main/CNN_Assg_Waste_Segregation_Starter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Waste Material Segregation for Improving Waste Management\n",
        "\n",
        "\n",
        "```\n",
        "Objective\n",
        "\n",
        "The objective of this project is to implement an effective waste material segregation system using convolutional neural networks (CNNs) that categorises waste into distinct groups. This process enhances recycling efficiency, minimises environmental pollution, and promotes sustainable waste management practices.\n",
        "\n",
        "The key goals are:\n",
        "\n",
        "    Accurately classify waste materials into categories like cardboard, glass, paper, and plastic.\n",
        "    Improve waste segregation efficiency to support recycling and reduce landfill waste.\n",
        "    Understand the properties of different waste materials to optimise sorting methods for sustainability.\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "a4YOL_I55tnc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Understanding"
      ],
      "metadata": {
        "id": "F_0qr0Vl7FWI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Dataset consists of images of some common waste materials.\n",
        "\n",
        "    Food Waste\n",
        "    Metal\n",
        "    Paper\n",
        "    Plastic\n",
        "    Other\n",
        "    Cardboard\n",
        "    Glass\n"
      ],
      "metadata": {
        "id": "N4bVIA9m7M_B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Data Description\n",
        "\n",
        "    The dataset consists of multiple folders, each representing a specific class, such as Cardboard, Food_Waste, and Metal.\n",
        "    Within each folder, there are images of objects that belong to that category.\n",
        "    However, these items are not further subcategorised.\n",
        "    For instance, the Food_Waste folder may contain images of items like coffee grounds, teabags, and fruit peels, without explicitly stating that they are actually coffee grounds or teabags.\n",
        "\n"
      ],
      "metadata": {
        "id": "Mm8iZM5e7QGK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Load the data\n",
        "\n",
        "Load and unzip the dataset zip file.\n"
      ],
      "metadata": {
        "id": "TeAb34SU7XqS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Necessary Libraries"
      ],
      "metadata": {
        "id": "z1WyueBh7c9V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recommended versions:\n",
        "\n",
        "# numpy version: 1.26.4\n",
        "# pandas version: 2.2.2\n",
        "# seaborn version: 0.13.2\n",
        "# matplotlib version: 3.10.0\n",
        "# PIL version: 11.1.0\n",
        "# tensorflow version: 2.18.0\n",
        "# keras version: 3.8.0\n",
        "# sklearn version: 1.6.1"
      ],
      "metadata": {
        "id": "MBIOL1jH7i0h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pGKThJ2W1KAX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os # Import the os module\n",
        "import cv2\n",
        "import sklearn\n",
        "from PIL import Image as im\n",
        "from glob import glob\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "import keras\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.models import Model\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import Model\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import zipfile # Import the zipfile module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0E0EzHb1hry",
        "outputId": "996160ab-63e7-4242-e4a6-d587fad9a6b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "print(os.getcwd())\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VK8zxQu216E8"
      },
      "outputs": [],
      "source": [
        "# Load and unzip the dataset\n",
        "# Assuming the dataset zip file is named 'waste_dataset.zip'\n",
        "# Uncomment the following lines when working with the actual zip file\n",
        "\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/Colab_Notebooks/data.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('Garbage_classification')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypk_BQ4E11W4"
      },
      "outputs": [],
      "source": [
        "# Path to the dataset directory\n",
        "#dataset_path = 'Garbage_classification/data/Paper'  # Update this path as needed\n",
        "import os\n",
        "data_path = '/content/Garbage_classification/data'\n",
        "os.listdir(data_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5UQQbkW4obU"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "img_height = 128\n",
        "img_width = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpYr5HLt4fGf"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_path,\n",
        "    validation_split = 0.2,\n",
        "    subset = 'training',\n",
        "    label_mode = 'categorical',\n",
        "    image_size = (img_height, img_width),\n",
        "    batch_size = BATCH_SIZE,\n",
        "    seed = 123,\n",
        "    #Limit the number of training samples\n",
        "    #labels = ['0', '1', '2', '3', '4', '5'][:2000] #Limit the number of labels to 2000)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccuUC0Zh4_qi"
      },
      "outputs": [],
      "source": [
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_path,\n",
        "    validation_split = 0.2,\n",
        "    subset = 'validation',\n",
        "    label_mode = 'categorical',\n",
        "    image_size = (img_height, img_width),\n",
        "    batch_size = BATCH_SIZE,\n",
        "    seed = 123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BXzV6X055H2K"
      },
      "outputs": [],
      "source": [
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ucpDY9d38vO"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "  for i in range(len(class_names)):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[i])\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ScOnuW3V5N-g"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "data_augmentation = keras.Sequential([\n",
        "    #layers.CenterCrop(125, 125),\n",
        "    layers.RandomFlip('horizontal', input_shape = (img_height, img_width, 3)),\n",
        "    layers.RandomRotation(0.2, fill_mode = 'nearest'),\n",
        "    layers.RandomZoom(0.1),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZH8p-TL5ebl"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for images, _ in train_ds.take(1):\n",
        "  for i in range(len(class_names)):\n",
        "    augmented_images = data_augmentation(images)\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
        "   # plt.title(class_names[2])\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zJChC1S5lSB"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size = AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size = AUTOTUNE)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zRGmaVk5qIp"
      },
      "outputs": [],
      "source": [
        "# Create the base model from the pre-trained model MobileNet V2\n",
        "IMG_SHAPE = (img_height, img_width, 3)\n",
        "base_model = tf.keras.applications.VGG16(input_shape = IMG_SHAPE,\n",
        "                                         include_top = False,\n",
        "                                         weights = 'imagenet')\n",
        "#base_model.trainable = False\n",
        "base_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSbLpxq15sbk"
      },
      "outputs": [],
      "source": [
        "def print_layer_trainable():\n",
        "    for layer in base_model.layers:\n",
        "        print(\"{0}:\\t{1}\".format(layer.trainable, layer.name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVkkRlGJ5xd2"
      },
      "outputs": [],
      "source": [
        "print_layer_trainable()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCLmvuhI50vt"
      },
      "outputs": [],
      "source": [
        "# Unfreeze some layers of the base model\n",
        "#base_model.trainable = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGBB7ye-57Q7"
      },
      "outputs": [],
      "source": [
        "base_model.trainable = False\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    if 'block5' in layer.name or 'block4' in layer.name:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHbozc1N2Y7s"
      },
      "outputs": [],
      "source": [
        "data_augmentation = keras.Sequential([\n",
        "    layers.RandomFlip('horizontal', input_shape = (img_height, img_width, 3)),\n",
        "    layers.RandomRotation(0.2, fill_mode = 'nearest'),\n",
        "    layers.RandomZoom(0.1),\n",
        "    layers.RandomContrast(0.2),  # Added random contrast adjustment\n",
        "    # Add more augmentation techniques as needed\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2c6vWyW-5_uU"
      },
      "outputs": [],
      "source": [
        "n_classes = len(class_names)\n",
        "\n",
        "model = Sequential([\n",
        "    data_augmentation,\n",
        "    layers.Rescaling(1./255),\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(128, activation = 'relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(n_classes, activation = 'softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHXSAW986ECI"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQwS-vAU6GPv"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import mixed_precision\n",
        "policy = mixed_precision.Policy('mixed_float16')\n",
        "mixed_precision.set_global_policy(policy)\n",
        "\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size = AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size = AUTOTUNE)\n",
        "\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0001),\n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics = ['accuracy'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0yY36ng36KEg"
      },
      "outputs": [],
      "source": [
        "# Model Chackpoint\n",
        "tl_checkpoint_1 = ModelCheckpoint(filepath = 'vgg16_best_weights.hdf5.keras', save_best_only = True, verbose = 0)\n",
        "\n",
        "# EarlyStopping\n",
        "early_stop = EarlyStopping(monitor = 'val_loss', patience = 5, restore_best_weights = True, mode = 'min')\n",
        "\n",
        "# Import ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "# ReduceLROnPlateau\n",
        "rop_callback = ReduceLROnPlateau(monitor = 'val_loss', patience = 2,  # Reduced patience\n",
        "                                verbose = 1, factor = 0.5, min_lr = 0.000001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q21E-JG36hW7"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "%%time\n",
        "history = model.fit(train_ds,\n",
        "                    epochs = 10,\n",
        "                    validation_data = val_ds,\n",
        "                    callbacks = [tl_checkpoint_1, early_stop, rop_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LeCNRxe_-1I"
      },
      "outputs": [],
      "source": [
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_path,\n",
        "    label_mode = 'categorical',\n",
        "    image_size = (img_height, img_width),\n",
        "    batch_size = 1,\n",
        "    seed = 123)\n",
        "\n",
        "test_ds = test_ds.cache().prefetch(buffer_size = AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irVHB-239D6H"
      },
      "outputs": [],
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(10)\n",
        "\n",
        "plt.figure(figsize = (10, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label = 'Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label = 'Validation Accuracy')\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label = 'Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label = 'Validation Loss')\n",
        "plt.legend(loc = 'upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_path,\n",
        "    label_mode = 'categorical',\n",
        "    image_size = (img_height, img_width),\n",
        "    batch_size = 1,\n",
        "    seed = 123)\n",
        "\n",
        "test_ds = test_ds.cache().prefetch(buffer_size = AUTOTUNE)"
      ],
      "metadata": {
        "id": "pu_fluHSkefA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RadmX1aEAT0D"
      },
      "outputs": [],
      "source": [
        "# Generate predictions\n",
        "model.load_weights('/content/vgg16_best_weights.hdf5.keras') # initialize the best trained weights\n",
        "preds = model.predict(test_ds)\n",
        "pred_classes = np.argmax(preds, axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OS82BggTCVYN"
      },
      "outputs": [],
      "source": [
        "model.evaluate(test_ds, verbose = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFzAUErlCaXV"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "img_height = 128\n",
        "img_width = 128\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def print_layer_trainable(): # Defining the function 'print_layer_trainable'\n",
        "    for layer in base_model.layers:\n",
        "        print(\"{0}:\\t{1}\".format(layer.trainable, layer.name))\n",
        "\n",
        "IMG_SHAPE = (img_height, img_width, 3)\n",
        "base_model = tf.keras.applications.VGG16(input_shape = IMG_SHAPE,\n",
        "                                         include_top = False,\n",
        "                                         weights = 'imagenet')\n",
        "\n",
        "\n",
        "fine_tune  = base_model\n",
        "\n",
        "\n",
        "fine_tune.trainable = True\n",
        "\n",
        "\n",
        "for layer in fine_tune.layers:\n",
        "    # Boolean whether this layer is trainable.\n",
        "    trainable = ('block5' in layer.name or 'block4' in layer.name)\n",
        "\n",
        "    # Set the layer's bool.\n",
        "    layer.trainable = trainable\n",
        "\n",
        "\n",
        "print_layer_trainable()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YicgUlRCfLE"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "fine_tune.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0CVrzOwWCjla"
      },
      "outputs": [],
      "source": [
        "n_classes = len(class_names)\n",
        "\n",
        "model2 = Sequential([\n",
        "    data_augmentation,\n",
        "    layers.Rescaling(1./255),\n",
        "    fine_tune,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(128, activation = 'relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(n_classes, activation = 'softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3mh8mIpClZ5"
      },
      "outputs": [],
      "source": [
        "model2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgpmV6A_Co6x"
      },
      "outputs": [],
      "source": [
        "model2.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001),\n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_4xQ8NPCvi9"
      },
      "outputs": [],
      "source": [
        "# Model Chackpoint\n",
        "tl_checkpoint_1 = ModelCheckpoint(filepath = 'vgg16_best_weights_fine_tuning.hdf5.keras', save_best_only = True, verbose = 0)\n",
        "\n",
        "# EarlyStopping\n",
        "early_stop = EarlyStopping(monitor = 'val_loss', patience = 10, restore_best_weights = True, mode = 'min')\n",
        "\n",
        "# Import ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "#ReduceLROnPlateau to stabilize the training process of the model\n",
        "rop_callback = ReduceLROnPlateau(monitor = 'val_loss', patience = 3, verbose = 1, factor = 0.5, min_lr = 0.000001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61-qguV3Czge"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "history = model2.fit(train_ds,\n",
        "                    epochs = 10,\n",
        "                    validation_data = val_ds,\n",
        "                    callbacks = [tl_checkpoint_1, early_stop, rop_callback])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(10)\n",
        "\n",
        "plt.figure(figsize = (10, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label = 'Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label = 'Validation Accuracy')\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label = 'Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label = 'Validation Loss')\n",
        "plt.legend(loc = 'upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dXNjb-Oum5h_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE # Define AUTOTUNE here using tf.data.AUTOTUNE\n",
        "\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    data_path,\n",
        "    label_mode = 'categorical',\n",
        "    image_size = (img_height, img_width),\n",
        "    batch_size = 1,\n",
        "    seed = 123)\n",
        "\n",
        "test_ds = test_ds.cache().prefetch(buffer_size = AUTOTUNE)"
      ],
      "metadata": {
        "id": "VrntFPrFnB5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions\n",
        "model2.load_weights('/content/vgg16_best_weights_fine_tuning.hdf5') # initialize the best trained weights\n",
        "preds = model2.predict(test_ds)\n",
        "pred_classes = np.argmax(preds, axis = 1)"
      ],
      "metadata": {
        "id": "LJ78uC3MnKw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.evaluate(test_ds, verbose = 1)"
      ],
      "metadata": {
        "id": "wnQBcBS9nP1h"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOoRdhTMj4Ao7I/9YgZDvhJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}